# -*- coding: utf-8 -*-
"""Agent_handson.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i9RXY4j3dl3fcABb_NVBRGuKJqoCK9gf
"""

import os
from google.colab import userdata
os.environ["OPENAI_API_KEY"] = userdata.get('sep_openai')

pip install langchain langchain-community transformers accelerate

from langchain.agents import initialize_agent, Tool
from langchain.agents.agent_types import AgentType
from langchain.memory import ConversationBufferMemory
from langchain.chat_models import ChatOpenAI

llm = ChatOpenAI(temperature=0)

def simple_calc(input: str) -> str:
    return str(eval(input))

tools = [
    Tool(
        name="Calculator",
        func=simple_calc,
        description="Useful for basic math like addition, multiplication, etc."
    )
]

memory = ConversationBufferMemory(memory_key="chat_history")

agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,
    verbose=True,
    memory=memory
)

response1 = agent.run("What is 24 * 17?")
print("Agent:", response1)

response2 = agent.run("Now add 100 to it.")
print("Agent:", response2)

response3 = agent.run("Repeat what we discussed so far.")
print("Agent:", response3)

response3 = agent.run("Repeat what we discussed so far.")
print("Agent:", response3)

### Calc-> addition,sub,multipl,division

### Try for statistic based tool

!pip install duckduckgo-search

pip install -U ddgs

from langchain_community.tools import DuckDuckGoSearchRun

### File Reader
def file_reader_tool(query: str) -> str:
    try:
        with open("/content/training_data.txt", "r") as file:
            content = file.read()
            return content[:1000]
    except Exception as e:
        return f"Error reading file: {str(e)}"

#websearch
search = DuckDuckGoSearchRun()

tools = [

    Tool(
        name="FileReader",
        func=file_reader_tool,
        description="Reads content from a local text file called sample.txt."
    ),
    Tool(
        name="WebSearch",
        func=search.run,
        description="Useful for answering questions about current events or facts using the internet."
    )
]

agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

print(agent.run("Read the file and tell me its content."))

print(agent.run("Who is the current CEO of OpenAI?"))

print(agent.run("Who is the current CEO of OpenAI?Use websearch"))

print(agent.run("Who is Premalatha,Corporate Trainer for AI?"))

print(agent.run("Who is the current CEO of OpenAI?Use filesearch only"))

agent.run("Read the file and summarize the first 3 sentences")

agent.run("Howmany times the word AI occu in this document")

agent.run("Show me top 5 trending technologies today,2025")

agent.run("create 10 mcqs on generative ai for BE students")

### Debug the above

### web search for linkedin

agent.run("https://www.linkedin.com/in/latha-t-k-b21018128/")

### unhappy with this agent

### 2)Web agent

### define a function to extract text from url
### Create a tool
### initialize the agent
### Check and update

import requests
from bs4 import BeautifulSoup

# For creating the agent
from langchain.agents import initialize_agent, Tool, AgentType
from langchain.chat_models import ChatOpenAI

def extract_website_text(url):
  response = requests.get(url)
  soup = BeautifulSoup(response.text, "html.parser")
  return soup.get_text()

def website_qa_tool(url_and_question):
        url, question = url_and_question.split("|", 1)
        content = extract_website_text(url.strip())
        prompt = f"Answer this question using the content from the website:\n\n{question.strip()}\n\nContent:\n{content[:6000]}"
        llm = ChatOpenAI()
        return llm.predict(prompt)


# STEP 3.2 CREATE THE TOOL FOR THE AGENT USING THE FUNCTION CREATED

tool = Tool(
    name="WebsiteQnA",
    func=website_qa_tool,
    description="Input format: ' | '. Use this tool to ask questions about any website's content."

)

# STEP 4: INITIALIZE THE AGENT

agent = initialize_agent(
    tools=[tool],
    llm=ChatOpenAI(),
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True,
    handle_parsing_errors=True
)

agent.run("https://www.oracle.com/database/ | Summarize Oracle Database features in 3 bullet points.")

agent.run("https://www.oracle.com/cloud/ | What are the benefits of Oracle Cloud?")

### Compare 2 oracle pages
### wikipedia
### Compare both comeup with a combined summary

!pip install langchain_openai

!pip install langchain_experimental

from langchain.agents.agent_types import AgentType
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent
from langchain_openai import ChatOpenAI

import pandas as pd
from langchain_openai import OpenAI

df = pd.read_csv(
    "https://raw.githubusercontent.com/Premalatha-success/Datasets/refs/heads/main/CardioGoodFitness-1.csv"
)

df.head()

agent = create_pandas_dataframe_agent(llm, df, verbose=True, allow_dangerous_code=True)

agent.run("How many rows are there?")

agent.run("Show the record of the eldest?")

df1=df.copy()

agent=create_pandas_dataframe_agent(llm, [df, df1], verbose=True,allow_dangerous_code=True)

agent.run("Min age in df1 and df?")

### Capstone Project: RAG Agent/ Usecase